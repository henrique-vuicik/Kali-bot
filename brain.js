// brain.js â€” ES Module
import OpenAI from 'openai';

const client = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });
const OPENAI_MODEL = process.env.OPENAI_MODEL || 'gpt-4o-mini';

// memÃ³ria ingÃªnua por usuÃ¡rio em RAM
const memory = new Map();
function getHistory(id) { return memory.get(id) || []; }
function pushMemory(id, role, content) {
  const arr = getHistory(id);
  arr.push({ role, content });
  while (arr.length > 12) arr.shift();
  memory.set(id, arr);
}

function sys(name='Paciente') {
  return [
    'VocÃª Ã© a Kali, assistente de nutrologia do Dr. Henrique Vuicik.',
    'Fale em portuguÃªs, breve, empÃ¡tica e orientativa.',
    'Evite diagnÃ³sticos fechados; priorize educaÃ§Ã£o e seguranÃ§a.',
    'Para casos clÃ­nicos, sugira avaliaÃ§Ã£o com o mÃ©dico.',
    `O usuÃ¡rio chama-se ${name}.`
  ].join(' ');
}

export async function aiReply(wa_id, userText, profileName='Paciente') {
  // sem chave? devolve resposta simples para nÃ£o quebrar
  if (!process.env.OPENAI_API_KEY) {
    return 'Oi! Sou a Kali ðŸ˜Š. Posso ajudar com nutrologia e hÃ¡bitos. Conte-me sua dÃºvida.';
  }

  pushMemory(wa_id, 'user', userText);

  const messages = [
    { role: 'system', content: sys(profileName) },
    ...getHistory(wa_id).map(m => ({ role: m.role, content: m.content }))
  ];

  try {
    const resp = await client.chat.completions.create({
      model: OPENAI_MODEL,
      messages,
      max_tokens: 300,
      temperature: 0.5
    });
    const text =
      resp.choices?.[0]?.message?.content?.trim() ||
      'Entendi! Como posso te ajudar?';
    pushMemory(wa_id, 'assistant', text);
    return text;
  } catch (e) {
    console.error('Erro na IA:', e);
    return 'Tive um probleminha para pensar nisso agora ðŸ˜…. Pode repetir em outras palavras?';
  }
}